input: "data"
input_shape{dim: 2 dim: 1 dim: 128 dim: 128 dim: 64}

input: "label"
input_shape{dim: 2 dim: 1 dim: 128 dim: 128 dim: 64}


layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pooling1"
  type: "Convolution"
  bottom: "conv1"
  top: "pooling1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res1"
  type: "Convolution"
  bottom: "pooling1"
  top: "res1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pooling2"
  type: "Convolution"
  bottom: "res1"
  top: "pooling2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2"
  type: "Convolution"
  bottom: "pooling2"
  top: "res2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pooling3"
  type: "Convolution"
  bottom: "res2"
  top: "pooling3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3"
  type: "Convolution"
  bottom: "pooling3"
  top: "res3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "depooling1"
  type: "Deconvolution"
  bottom: "res3"
  top: "depooling1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "add1"
  type: "Eltwise"
  bottom: "depooling1"
  bottom: "res2"
  top: "add1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4"
  type: "Convolution"
  bottom: "add1"
  top: "res4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "depooling2"
  type: "Deconvolution"
  bottom: "res4"
  top: "depooling2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "add2"
  type: "Eltwise"
  bottom: "depooling2"
  bottom: "res1"
  top: "add2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res5"
  type: "Convolution"
  bottom: "add2"
  top: "res5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "depooling3"
  type: "Deconvolution"
  bottom: "res5"
  top: "depooling3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "add3"
  type: "Eltwise"
  bottom: "depooling3"
  bottom: "conv1"
  top: "add3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res6"
  type: "Convolution"
  bottom: "add3"
  top: "res6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "output"
  type: "Convolution"
  bottom: "res6"
  top: "output"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "data_flat"
  type: "Reshape"
  bottom: "output"
  top: "data_flat"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: 1048576
    }
  }
}
layer {
  name: "label_flat"
  type: "Reshape"
  bottom: "label"
  top: "label_flat"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 1048576
    }
  }
}
layer {
  name: "softmax_out"
  type: "Softmax"
  bottom: "data_flat"
  top: "softmax_out"
}

layer {
  type: 'Python'
  name: 'loss'
  top: 'loss'
  bottom: 'softmax_out'
  bottom: "label_flat"

  python_param {
    # the module name -- usually the filename -- that needs to be in $PYTHONPATH
    module: 'pyLayer'
    # the layer name -- the class name in the module
    layer: 'DiceLoss'
  }
  # set loss weight so Caffe knows this is a loss layer.
  # since PythonLayer inherits directly from Layer, this isn't automatically
  # known to Caffe
  loss_weight: 1
}