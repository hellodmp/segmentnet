input: "data"
input_shape{dim: 2 dim: 1 dim: 128 dim: 128 dim: 64}

input: "label"
input_shape{dim: 2 dim: 1 dim: 128 dim: 128 dim: 64}


layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat1"
  type: "Concat"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  bottom: "data"
  top: "concat1"
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "concat1"
  bottom: "conv1"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "block1"
  type: "PReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pooling1"
  type: "PReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "conv2"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "block2"
  type: "PReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pooling2"
  type: "PReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU1"
  type: "PReLU"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "Convolution3"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Convolution2"
  bottom: "conv3"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "block3"
  type: "PReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pooling3"
  type: "PReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU2"
  type: "PReLU"
  bottom: "Convolution5"
  top: "Convolution5"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Convolution5"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU3"
  type: "PReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "Convolution6"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution4"
  bottom: "conv4"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "block4"
  type: "PReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pooling4"
  type: "PReLU"
  bottom: "Convolution7"
  top: "Convolution7"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Convolution7"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU4"
  type: "PReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU5"
  type: "PReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "Convolution9"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution7"
  bottom: "conv5"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "block5"
  type: "PReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Deconvolution1"
  type: "Deconvolution"
  bottom: "Eltwise5"
  top: "Deconvolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "depooling1"
  type: "PReLU"
  bottom: "Deconvolution1"
  top: "Deconvolution1"
}
layer {
  name: "concat5"
  type: "Concat"
  bottom: "Deconvolution1"
  bottom: "Eltwise4"
  top: "concat5"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "concat5"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU6"
  type: "PReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU7"
  type: "PReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "Convolution11"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "concat5"
  bottom: "conv6"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "block6"
  type: "PReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Deconvolution2"
  type: "Deconvolution"
  bottom: "Eltwise6"
  top: "Deconvolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "depooling2"
  type: "PReLU"
  bottom: "Deconvolution2"
  top: "Deconvolution2"
}
layer {
  name: "concat6"
  type: "Concat"
  bottom: "Deconvolution2"
  bottom: "Eltwise3"
  top: "concat6"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "concat6"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU8"
  type: "PReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "Convolution12"
  top: "conv7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "concat6"
  bottom: "conv7"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "block7"
  type: "PReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Deconvolution3"
  type: "Deconvolution"
  bottom: "Eltwise7"
  top: "Deconvolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "depooling3"
  type: "PReLU"
  bottom: "Deconvolution3"
  top: "Deconvolution3"
}
layer {
  name: "concat7"
  type: "Concat"
  bottom: "Deconvolution3"
  bottom: "Eltwise2"
  top: "concat7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "concat7"
  top: "conv8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "concat7"
  bottom: "conv8"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "block8"
  type: "PReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Deconvolution4"
  type: "Deconvolution"
  bottom: "Eltwise8"
  top: "Deconvolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "depooling4"
  type: "PReLU"
  bottom: "Deconvolution4"
  top: "Deconvolution4"
}
layer {
  name: "concat8"
  type: "Concat"
  bottom: "Deconvolution4"
  bottom: "Eltwise1"
  top: "concat8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "concat8"
  top: "conv9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "concat8"
  bottom: "conv9"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "block9"
  type: "PReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "output"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "output"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "data_flat"
  type: "Reshape"
  bottom: "output"
  top: "data_flat"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: 1048576
    }
  }
}
layer {
  name: "label_flat"
  type: "Reshape"
  bottom: "label"
  top: "label_flat"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 1048576
    }
  }
}
layer {
  name: "softmax_out"
  type: "Softmax"
  bottom: "output"
  top: "softmax_out"
}

layer {
  type: 'Python'
  name: 'loss'
  top: 'loss'
  bottom: 'softmax_out'
  bottom: "label_flat"

  python_param {
    # the module name -- usually the filename -- that needs to be in $PYTHONPATH
    module: 'pyLayer'
    # the layer name -- the class name in the module
    layer: 'DiceLoss'
  }
  # set loss weight so Caffe knows this is a loss layer.
  # since PythonLayer inherits directly from Layer, this isn't automatically
  # known to Caffe
  loss_weight: 1
}